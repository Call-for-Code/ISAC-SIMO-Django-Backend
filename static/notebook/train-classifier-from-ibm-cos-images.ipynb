{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISAC-SIMO-sample-model-generation-ibm-cos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH5EKJhqr1gz"
      },
      "source": [
        "### Image Classification Model (.h5) Generation for Go or No Go (Sample Example)\n",
        "## Uses images from **IBM COS (Bucket)** labeled using **IBM Cloud Annotations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79UE8NLVvl7g"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHQyc83kr1g7"
      },
      "source": [
        "credentials = {\n",
        "  \"bucket\": \"<bucket_name>\",\n",
        "  \"access_key_id\": \"<access_key_id>\",\n",
        "  \"secret_access_key\": \"<secret_access_key>\",\n",
        "  \"endpoint_url\": \"<endpoint_url>\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNDUCpkfr1g0"
      },
      "source": [
        "## Install Prerequisites\n",
        "\n",
        "We use Keras/Tensorflow to build the classification model, and visualize the process with matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xjPdHZor1g1"
      },
      "source": [
        "!pip install tensorflow==2.5.0 ibm-cos-sdk==2.6 h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6H0k7V3r1g4"
      },
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import uuid\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "import ibm_boto3\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XnKLRuRr1g6"
      },
      "source": [
        "## Read The Data\n",
        "\n",
        "Here we build simple wrapper functions to read in the data from our cloud object storage buckets and extract it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCV4Wy2rr1g-"
      },
      "source": [
        "A download function from IBM Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf1Ms-Lgr1g-"
      },
      "source": [
        "def download_file_cos(credentials, local_file_name, key): \n",
        "    '''\n",
        "    Wrapper function to download a file from cloud object storage using the\n",
        "    credential dict provided and loading it into memory\n",
        "    '''\n",
        "    cos = ibm_boto3.client(\n",
        "        service_name='s3',\n",
        "        aws_access_key_id=credentials['access_key_id'],\n",
        "        aws_secret_access_key=credentials['secret_access_key'],\n",
        "        endpoint_url=credentials['endpoint_url'])\n",
        "    try:\n",
        "        res=cos.download_file(Bucket=credentials['bucket'], Key=key, Filename=local_file_name)\n",
        "    except Exception as e:\n",
        "        print(Exception, e)\n",
        "    else:\n",
        "        print('File Downloaded')\n",
        "\n",
        "def get_annotations(credentials): \n",
        "    cos = ibm_boto3.client(\n",
        "        service_name='s3',\n",
        "        aws_access_key_id=credentials['access_key_id'],\n",
        "        aws_secret_access_key=credentials['secret_access_key'],\n",
        "        endpoint_url=credentials['endpoint_url'])\n",
        "    try:\n",
        "        return json.loads(cos.get_object(Bucket=credentials['bucket'], Key='_annotations.json')['Body'].read())\n",
        "    except Exception as e:\n",
        "        print(Exception, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfBjP61Mr1hB"
      },
      "source": [
        "base_path = 'data'\n",
        "if os.path.exists(base_path) and os.path.isdir(base_path):\n",
        "    shutil.rmtree(base_path)\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "annotations = get_annotations(credentials)\n",
        "\n",
        "for i, image in enumerate(annotations['annotations'].keys()):\n",
        "    label = annotations['annotations'][image][0]['label']\n",
        "    os.makedirs(os.path.join(base_path, label), exist_ok=True)\n",
        "    _, extension = os.path.splitext(image)\n",
        "    local_path = os.path.join(base_path, label, str(uuid.uuid4()) + extension)\n",
        "    download_file_cos(credentials, local_path, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1HMNpZYr1hD",
        "scrolled": true
      },
      "source": [
        "print(\"NO GO:\")\n",
        "!ls data/nogo\n",
        "print(\"GO:\")\n",
        "!ls data/go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qpYZMNer1hG"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "We start with a [MobileNetV2](https://arxiv.org/abs/1801.04381) architecture as the backbone [pretrained feature extractor](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet). We then add a couple of dense layers and a softmax layer to perfom the classification. We freeze the MobileNetV2 backbone with weights trained on ImageNet dataset and only train the dense layers and softmax layer that we have added.\n",
        "\n",
        "Configuration needs to change depending on the image size and aspect ratio. Or you might use other backbone or libraries for training and exporting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN_FY40Dr1hG"
      },
      "source": [
        "base_model=tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), alpha=1.0) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "x=base_model.output\n",
        "x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x=tf.keras.layers.Dense(512,activation='relu')(x) #dense layer 1\n",
        "x=tf.keras.layers.Dense(256,activation='relu')(x) #dense layer 2\n",
        "preds=tf.keras.layers.Dense(3,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=tf.keras.Model(inputs=base_model.input,outputs=preds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApSMk3W2r1hJ"
      },
      "source": [
        "#Freeze layers from MobileNetV2 backbone (not to be trained)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHEvYJARr1hM"
      },
      "source": [
        "#Prepare the training dataset as a data generator object\n",
        "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('data',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=10,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv_R_SCFr1hO"
      },
      "source": [
        "#### Using Adam, categorical_crossentropy and accuracy as optimization method, loss function and metrics, respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93AFFFdtr1hO"
      },
      "source": [
        "# Build the model\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjj9cjU3r1hR"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exRobg6cr1hS",
        "scrolled": false
      },
      "source": [
        "from tensorflow.random import set_seed\n",
        "set_seed(3)\n",
        "step_size_train=1\n",
        "epochs=1\n",
        "log_file = model.fit(train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNRpVg-zr1hU"
      },
      "source": [
        "## Figure of Training Loss and Accuracy\n",
        "Plotting the training result as below (if required)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C6J2Gubr1hV"
      },
      "source": [
        "# # Model accuracy and loss vs epoch\n",
        "# plt.plot(log_file.history['acc'], '-bo', label=\"train_accuracy\")\n",
        "# plt.plot(log_file.history['loss'], '-r*', label=\"train_loss\")\n",
        "# plt.title('Training Loss and Accuracy')\n",
        "# plt.ylabel('Loss/Accuracy')\n",
        "# plt.xlabel('Epoch #')\n",
        "# plt.legend(loc='center right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3pu-2Ddr1hX"
      },
      "source": [
        "## Model Performance\n",
        "\n",
        "Here we perform inference on some sample data points to determine the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD_GuzqAr1hX"
      },
      "source": [
        "# Mapping labels \n",
        "label_map = (train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl-eHspBr1hZ"
      },
      "source": [
        "label_map\n",
        "# Returns Example: {'go': 0, 'nogo': 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQENLlakr1hc"
      },
      "source": [
        "# Creating a sample inference function\n",
        "def prediction(image_path, model):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    # print('Predictions', preds)\n",
        "    \n",
        "    #  Printing the prediction score and class\n",
        "    # for pred, value in label_map.items():    \n",
        "    #     if value == np.argmax(preds):\n",
        "    #         print('Predicted class is:', pred)\n",
        "    #         print('With a confidence score of: ', np.max(preds))\n",
        "\n",
        "    # Format the Output as required by ISAC-SIMO Offline Model (Classifier)\n",
        "    # https://www.isac-simo.net/app/offline_model/readme.md#classifier-without-pre-post-process\n",
        "    if np.argmax(preds) == 0:\n",
        "      return [[np.max(preds), 0]]\n",
        "    elif np.argmax(preds) == 1:\n",
        "      return [[0, np.max(preds)]]\n",
        "    else:\n",
        "      return [[0, 0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJ3EsC0r1he"
      },
      "source": [
        "# Download some Sample Images (Example: Stirrup)\n",
        "go_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Stirrup_sample.png/220px-Stirrup_sample.png'\n",
        "nogo_url = 'https://www.zbms.co.zw/wp-content/uploads/2018/06/230-by-230-rebar-stirrups-links-for-sale-in-Harare-Zimbabwe-1.jpg'\n",
        "!wget {go_url} -O go.jpg \n",
        "!wget {nogo_url} -O nogo.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lhwp01Fr1hs"
      },
      "source": [
        "# Opening test image\n",
        "image = Image.open(\"go.jpg\")\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SH5afqlr1ht"
      },
      "source": [
        "prediction('go.jpg', model)\n",
        "# Returns Example: [[0.69597286, 0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvwkd5W6CV7A"
      },
      "source": [
        "# Generate and Download the .h5 Model\n",
        "from google.colab import files\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/new-ibm-test.h5')\n",
        "files.download('saved_model/new-ibm-test.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}